apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: llm
spec:
  predictor:
    timeout: 600
    containers:
      - name: kserve-container
        image: chasechristensen/tiledb_predictor:v1 #update with your image if self-hosting. 
        imagePullPolicy: Always
        # If you are running behind a proxy, uncomment the following lines and replace the values with your proxy URLs.
        # env:
        # - name: HTTP_PROXY
        #   value: <your http proxy URL>
        # - name: HTTPS_PROXY
        #   value: <your https proxy URL>
        # - name: NO_PROXY
        #   value: .local
        resources:
          requests:
            memory: "8Gi"
            cpu: "1000m"
          limits:
            memory: "8Gi"
            cpu: "1000m"
  transformer:
    timeout: 600
    containers:
      - image: chasechristensen/tiledb_transformer:v6 #update with your image if self-hosting. 
        imagePullPolicy: Always
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        name: kserve-container
