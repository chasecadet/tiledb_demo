Chapter 1. The Model Application Relationship and the Power of Reproducibility

Chapter Overview and Learning Objectives
Chapter 1 Overview 
If you didn’t watch the introduction video (and even if you did), welcome to this LFS147x! This course will prepare you for an exciting new role within the data world, whether that be a data scientist, machine learning engineer, or any other machine learning operations (MLOPs) role. The first path to success as a part of a machine-learning-oriented team is understanding the landscape of machine-learning development and deployment challenges. Still, since that topic is complex, we will take it one step at a time.

Learning Objectives
By the end of this chapter, you should be able to:
Discuss the importance of reproducibility and replicability
Explain the value behind applications' containerization in the context of replicability, reproducibility, and model deployment
Discuss the model and application relationship
Define the term “features” in the context of ML/AI
Models Versus Applications: Do We Still Need Both?
Model or Application?
Models and applications both work together to drive better business outcomes. New data professionals often have questions about how models and applications are related. Do we need applications if we have models? Do models replace the role of developers? This section will answer those questions by exploring how applications and models work together.
What is a Model?
A model takes data as a request and responds with a prediction based on learned patterns. Just like your brain tries to connect something it observes within the context of your life, the model takes in data and processes it to predict using its training experience. One typical example is a recommendation engine. A recommendation engine is a model that learns from your choices, like the movies you watch, to predict and suggest new ones you might like. It's like a friend who knows your tastes and recommends films based on what you've enjoyed. This engine constantly improves its suggestions by learning from your viewing history. In a recommendation model, the data includes user interaction data, such as items viewed, purchased, or rated; user demographic information; item attributes, like genre, author, and release date for movies or books; and sometimes contextual information, like the time of day or location. The prediction output contains items the user will likely be interested in. This prediction is based on analyzing the data to understand user preferences and behavior patterns and applying them to a distribution. In a movie recommendation system, the prediction could be the movies the user will likely enjoy watching based on their past viewing history and preferences.
Unpacking Predictions 
We have seen some need to clarify the term prediction when learning about machine learning predictions. A prediction is a formatted (often JSON, tensors, or arrays ) response from the model to the application.  The world of large language models like ChatGPT makes this even more confusing because the prediction can be a human-like text response rather than a simple numerical score or a class label typically expected from traditional models. In machine learning, a prediction is the output generated by a model after it has been trained on a dataset and then provided with new, unseen data. The nature of this output varies significantly depending on the model type and the specific task. For example, the prediction could be a category or label in a classification task, whereas in a regression task, it would be a continuous value. 
Types of Models
A recommendation engine is only one type of model. The input data format and the output prediction depend on the model and use case. Some models, like recommendation engines, often use a mix of techniques.

Some model examples are: 
Regression Models: For predicting continuous values, like sales forecasting or determining price trends.
Classification Models: Aimed at categorizing data into predefined classes, such as spam detection in emails or image recognition.
Clustering Models: These models identify inherent groupings in data, which are helpful in market segmentation or organizing large data sets.
Time Series Models: Specialized in analyzing time-ordered data to forecast future points in the series, like stock prices or weather predictions.
Dimensionality Reduction Models: Used to simplify data, reduce its complexity, and retain essential features, often used in data visualization.
Neural Networks: Inspired by the human brain, these models can learn complex patterns through layers of interconnected nodes, pivotal in deep learning applications like language translation or autonomous vehicles.
Are Models the Full Story?
The model is only part of the story regarding building intelligent applications. The model acts as the brain for our application. The application uses the model's response to determine logical flow, much like a human uses their brain to analyze a situation before using their body to execute their brain's determined actions. The application's logic is implemented based on the context of the model's outputs. The model application relationship is something that people new to the ML/AI world often find surprising. This surprise derives from their experience with the traditional software flow, where a developer finds patterns and uses data and code to drive an outcome. Data science teams take data and the determined outcome, then write code to build an algorithms-powered model. Instead of a developer hardcoding the desired inputs and outputs, the model learns patterns based on the data. The model also tests itself on how well it learned a concept and improved its known patterns during the training process—much like many of us do when studying for an exam or certification. We will go deeper into the model development lifecycle in future chapters. 
Our Sample Application
Pretend for a second that we are making an application whose job is to determine if a picture is or is not a duck and then sort the duck images into a “book of ducks.” Suppose you just went on a trip with your duck-loving friend and took 3000 pictures of waterfowl. You want to surprise your friend with a book of photographs containing all the ducks you encountered on your trip. However, you do not want to ruin the surprise by having your friend identify and sort the pictures. You also want to ensure this model works for others identifying ducks and potentially growing the duck-finding community! How might we go about this?
Duck Detection Application Attempt 
How would we start building our duck detection application without machine learning? 
The traditional software engineer might start by writing several loops and functions, attempting to find all the characteristics (or features) that identify a duck.
The code might look like the following:

// Pseudocode for Duck-or-Not-Duck Image Recognition
// Define the main function
function isItADuck(image):
    // Step 1: Check if the image is in the correct format
    if not isValidImageFormat(image):
    return "Error: Invalid image format. Please upload a JPG or PNG."

    // Step 2: Analyze the color spectrum of the image
    predominantColors = analyzePredominantColors(image)
    if "yellow" not in predominantColors:
    return "Probably not a duck. Ducks are often yellow."

    // Step 3: Look for the shape of a beak
    if not detectShape(image, "beak"):
    return "Probably not a duck. No beak detected."

    // Step 4: Check for presence of webbed feet
    if not detectShape(image, "webbed feet"):
    return "Might be a duck, but can't confirm without seeing webbed feet."

    // Step 5: Analyze the image for quacking sounds (just being silly)
    if detectSound(image, "quack"):
    return "Definitely a duck. It quacks!"

    // Step 6: Use advanced duck detection logic (very pseudo)
    if advancedDuckDetectionAlgorithm(image):
    return "Based on advanced analysis, this is indeed a duck."
    // If all else fails
    return "Uncertain if this is a duck. Please consult your duck watcher friend.".

A duck detection model may seem like a silly example, but let’s consider it for a moment. The pseudo application contained a loop that ended with consult your duck watcher friend, included some complex shape detection, and implemented advancedDuckDetectionAlgorithms. That code would be tricky to support. Identifying all possible images with and without ducks would be even more challenging. Imagine all the positions, environments, and quality of duck photos. An expert may also need to be consulted to identify many pictures, which can become complicated and expensive, defeating the application's purpose.
A Duck Image Detection Model
What if we train a model to be an automated version of your duck watcher friend? We would need a model that our application asks, “Is this a duck?” much like sifting through all the pictures with a duck expert while asking similar questions. How would we train a duck detection model? 

We still need a duck expert for the first step, which is to prepare the dataset. Machine learning teams spend much time finding and curating data; this project is no exception! We must first manually label images of ducks as duck or not_duck. This manual labeling step is called human in the loop. Initially, humans have to intervene in processes like image detection. Humans create the labels themselves. The model is only as good as the data and the human’s ability to develop valuable labels. Adjusting the data to improve the model is a data-centric approach to AI. Tuning the model to work better with the data is called a model-centric approach to AI.  Human-in-the-Loop Machine Learning by Robert (Munro) Monarch is an excellent resource if you want to learn more. 
Pseudocode for Duck or Not_Duck Detection Using Machine Learning
Continuing with our example, let's assume we have consulted an expert and have some labeled duck data that we trust. Now, let's look at some pseudocode for a duck-or-not-duck detection model that uses our duck data:

// Step 1: Prepare the labeled dataset
labeledData = loadDataset("duck_images_dataset.csv")
// Example dataset format: [image_path, label]
// label is either "duck" or "not_duck"

// Step 2: Preprocess the data
preprocessedData = preprocessData(labeledData)
// Preprocessing steps include resizing images, normalizing pixel values, etc.

// Step 3: Split the dataset into training and testing sets
trainSet, testSet = splitDataset(preprocessedData, trainSize=0.8)

// Step 4: Initialize the machine learning model
// For simplicity, let's assume we're using a convolutional neural network (CNN) suitable for image classification
model = initializeCNNModel()

// Step 5: Train the model on the training set
trainModel(model, trainSet)

// Step 6: Evaluate the model on the testing set to check its performance
evaluationResults = evaluateModel(model, testSet)
print("Model accuracy on test set:", evaluationResults.accuracy)

// Step 7: Use the trained model to predict new images
function predictDuck(image):
    preprocessedImage = preprocessImage(image)
    prediction = model.predict(preprocessedImage)
    if prediction == "duck":
        return "This is a duck."
    else:
        return "This is not a duck."

A Smarter Duck Detector
We are making progress! We have a model that can predict whether or not the image is or is not a duck. We are now ready to sort some pictures. Or are we? 

The model can determine if the image is or is not a duck, but then what? We still need to create a book of duck photographs with the pictures. This step requires an application. The application will use the model to get an is_duck or not_duck response like any other function call, but can then use that value to do something with the duck image.  


Here is an example of a prediction response from our duck detection model: 

{
  "prediction": "duck",
  "confidence": 0.95,
  "message": "This is a duck."
}
 
The prediction is the model's classification result, indicating that the image has been identified as a duck.
The confidence is a decimal value representing the model's confidence in its prediction, on a scale from 0 to 1, where 1 indicates absolute certainty. In this case, the model is 95% confident in its prediction.
The message provides a human-readable interpretation of the prediction, which directly corresponds to the outcome of the pseudo-code's conditional logic.



Pseudocode for an Application Calling a Duck Identification Model
Below is more pseudocode where our model puts the duck and not_duck images into a dictionary. We are using a dictionary for simplicity's sake, but the application will have the sorted pictures and can then build an online book or other output with those images.

// Step 1: Load the pre-trained duck identification model
model = loadModel("path/to/duck_identification_model")

// Step 2: Define the path for input images
inputImagePath = "path/to/input/images"

// Step 3: Process and predict each image in the input path
processImages(inputImagePath)

// Function to load the pre-trained model
function loadModel(modelPath):
	// Load and return the model from the specified path
	// This could involve deserializing the model file into a model object
	return model

// Function to process images in the specified path
function processImages(imagePath):
    // Retrieve a list of image files from the specified path
    imageFiles = getImageFiles(imagePath)
    
    // Loop through each image file
    for imageFile in imageFiles:
    // Load the image
    image = loadImage(imageFile)
   	 
    // Preprocess the image for the model
    preprocessedImage = preprocessImageForModel(image)
   	 
    // Predict if the image is a duck
    isDuck = predictDuck(preprocessedImage, model)
   	 
    // Initialize an empty dictionary to act as the fake "duck_book" object
    duck_book = {"duck": [], "not_duck": []}

    // Handle the prediction result
    if isDuck:
      print(imageFile + " is a duck.")
      duck_book["duck"].append(imageFile)
    else:
   	 print(imageFile + " is not a duck.")
    	 duck_book["not_duck"].append(imageFile)

And just like that, our duck detector can now sift through our images and create a book. You might be asking: 
How does a model detect ducks if we didn’t explain to it what a ”duck” is? 
Does our model look for specific feather patterns, colors, beak size, or plumage? 
Do we teach models to detect a duck the same way we teach humans? 

Deftly Dive into Duck Deep Learning 
We are about to go deeper (no pun intended) than we need to, but for those wondering how a deep learning model learns, this section will help build a foundational understanding. 

The model identifies ducks in images, not by explicitly searching for specific features like a "green bill" or "webbed feet', but by analyzing more abstract patterns and characteristics through its layers. Like onions, deep learning networks contain layers. Each layer activates specific nodes at certain magnitudes to pass information onto the next layer. The first layer is called the input layer, and the final layer is the output layer. In a Convolutional Neural Network (CNN), the initial layers may begin by detecting simple edges and textures.
In contrast, deeper layers combine these initial findings into more complex patterns that are not immediately recognizable to humans. These features would appear increasingly strange to humans as the data progresses through the network. The model learns these features during training by adjusting its internal parameters to reduce prediction errors, effectively identifying what combinations of abstract patterns map to a duck. The loss function is reduced through backpropagation and gradient descent to find a global minimum. The network leverages the chain rule for those who went through the pains of calculus. The chain rule is good for something besides tedious problem sets and is the star of backpropagation. The unique feature representation allows the model to generalize from the training data and accurately identify ducks in new, unseen images, even if the specific appearance varies widely from the examples it was trained on. We won’t need to go much deeper than that for this course. When using Kubeflow, we will have the power to use frameworks to build deep learning networks and kick-off training jobs. Here is a great video titled, "What is a Neural Network" that can help you digest this information if you are unfamiliar with deep learning or want to learn more. Again, do not worry if you don’t fully understand deep learning. It won’t impact your ability to succeed in this course. 
The Application Summarized
While our example was a vast oversimplification, think of the model as the brain and the application as the body, taking actions based on the brain's outputted predictions from the data it receives. The success of your application results from a delicate balance between the application and the model. The model could be embedded in the application lifecycle or operate as a model as a service, where it is deployed as a cloud endpoint. 
Managing both the model lifecycle and application lifecycle can be complex, especially as we look to minimize technical debt. Technical debt is one of the consequences of prioritizing quick, immediate solutions in coding over more thorough, sustainable approaches. It involves a balance between solving problems fast and avoiding the creation of future issues due to hastily written code. Ignoring technical debt can lead to increased costs and complications. As the system evolves, integrating new features with old code becomes more difficult and expensive, similar to how unpaid loans accumulate interest over time. If you want to learn about machine learning technical debt, check out this Google research paper: "Machine Learning: The High Interest Credit Card of Technical Debt".

Machine Learning Features and Feature Stores
Features 
The term feature is one of those overloaded words in technology. Professionals from the application development world can justifiably confuse application features (i.e., specific functionalities or capabilities within a software application) with data science features ( the detailed attributes and indicators data scientists discover within datasets). This section seeks to demystify what we mean by features when exploring datasets during model development.

When we created the Duck Detection Application earlier, we glossed over the features concept, but it is worth revisiting. In machine learning, features are like specific pieces of information that help the computer recognize patterns or make decisions—almost like clues in a puzzle that the computer uses to learn from data. For example, in our machine learning model designed to identify ducks, features might include the color of the feathers, the shape of the beak, the size of the duck, and the pattern of its quack. Each of these characteristics (or features) helps the computer learn to recognize whether a given image or sound is of a duck. The strange part of deep learning we discussed is that the features the deep learning network finds aren’t human-inputted. The network finds unique pixel mappings, edge detections, etc. Computers see the world differently. If we were to print the features the network finds and show them to a human, they wouldn’t think, “Of course, that is how you identify a duck.” Instead, a human might say, “What a bunch of gibberish!”. The complex nature of deep learning is why you might hear people referring to deep learning networks as “black boxes” since humans cannot easily interpret the model’s logic. 

Feature Stores 
You may have heard of feature stores while exploring the ML/AI world. The feature store most widely adopted in the Kubeflow community is Feast, which is in alpha. The concept of a feature store is more closely associated with traditional machine learning workflows. It is a centralized location where engineered features are stored, managed, and accessed. These features are manually designed and extracted from the data before being used to train models. We will not go into any more details on the nature of feature stores or the Feast project, but If you want more information on Kubeflow’s features store integrations, you can explore the Kubeflow Documentation.  Additionally, this Kaggle competition blog can help you understand a day in the life of a data scientist and where features come into play during model development.

The Value of Replicable, Reproducible, and Reliable Models
Developing and Deploying our Duck Classifier
As we dive into developing and deploying our duck detection model, we may improve it and make it a more robust Duck Classifier model, where we not only detect ducks but sort them into categories based on what type of duck they are. But before we go further, it's crucial to understand the principles of reproducibility and replicability. These concepts ensure our model's integrity and reliability and enhance its usability in real-world applications. This section will define these terms within the framework of our new duck classifier project and how containerization can help support our reproducibility and replicability objectives.
Reproducibility
In our Duck Classifier model, reproducibility means using the same dataset of duck and non-duck images, along with the identical model architecture and parameters, to achieve the same accuracy and performance metrics. This principle ensures that other developers or researchers can validate our findings and trust the model's reliability when using our exact setup. Achieving reproducibility involves meticulous documentation of our model's architecture (something many engineers dread), the training process, and the dataset used—ensuring that anyone with access to our resources can replicate our experiment with the same outcome. This step is critical for establishing the model's credibility and collaborative potential. Imagine a scenario where the next iteration of our duck model (the Duck Classifier) starts identifying ordinary mallards as rare mandarin ducks based on slight variations in lighting or background. Our predictions could lead to misinformed birdwatching enthusiasts, inadequate data collection for conservation efforts, or frustrated educators trying to engage students. Reproducibility ensures that it behaves as expected when we deploy our model in a classroom, a research project, or a mobile app for bird enthusiasts—delivering reliable and consistent classifications of ducks and non-duck entities alike.
Replicability
Replicability involves testing our Duck Classifier model with new, unseen datasets of bird images while maintaining the same model systems and expecting similar performance levels. This step is critical for demonstrating the model's utility across diverse real-world scenarios beyond the controlled conditions of the initial training set. Challenges in replicability include sourcing relevant and sufficiently varied new data that accurately represents the broader application context of duck identification—for instance, introducing images from different geographical locations, captured under various lighting conditions, or featuring ducks in dynamic postures. Successfully replicating our model's performance on new data underlines its robustness and adaptability. These are essential qualities for a tool designed for enthusiasts, researchers, and conservationists who may leverage your model.


Reproducibility versus Replicability
ALT= “Graphic showing the difference between Reproducibility and Replicability continuing the example of the duck identifier”
Determinism
Reproducibility and replicability are two concepts that are closely related and fundamental concepts when it comes to scientific rigor and the model development lifecycle. This topic gets tricky when discussing determinism, which refers to the principle that any process or algorithm operates predictably, producing the same output for a given input every time. An algorithm's initial conditions, parameters, and input data determine its behavior without any randomness or unpredictability in its execution or outcomes. In deterministic machine learning models, if you replicate the training process with the same data and parameters, you will always obtain the same model with weights and biases, leading to identical predictions for the same input data. Determinism is crucial in contexts where reproducibility and consistency of results are essential, such as in safety-critical applications or when diagnosing issues and improving models. Here is a wonderful GTC Silicon Valley talk on the topic to learn more. 
Containerization and Reproducibility
The quest for reproducibility is a shared goal in site reliability and software engineering. Reproducibility illuminates how systems “scale and fail”, which paves the way for innovations in reliability through technologies like containerization. Gone are the "well, it worked on my machine" discussions. Containerization brings a level of consistency and security previously unattainable, allowing us to build and deploy applications and, by extension, our Duck Classifier model that we know will run across the wild west of customer environments. Deploying our Duck Classifier model becomes a streamlined process, capable of execution anywhere a container runtime exists.  Adopting a model registry akin to MLflow or utilizing object storage like MinIO enhances our model's reproducibility and manageability. These tools allow us to serialize and store our Duck Classifier model, making it readily deployable consistently, mirroring the containerization strategies of traditional applications. The serialization of models is an entirely different art form we will touch upon later. Still, it is how we can efficiently store our models and use a serverless pattern to pull a model and deploy it similarly to a container. 
Containerization and Security
Containerization's ability to build an application (or model) in different locations yet achieve identical outcomes verifiable by hashing is revolutionary.  Hashing with build tools allows us to bet on consistency and repeatability.  Two builds with the same inputs should output matching results—the term for identical inputs leading to similar outputs every time is idempotency. 
For a more in-depth explanation, consult Chapter 8:Release Engineering of The SRE Handbook.
A real-world example of the critical nature of containerization is the infamous SolarWinds hack. Had the team built its update twice in two places and hashed them, they might have noticed the malicious code injection. Hashing ensures the integrity of build systems and safeguards against compromise. In our scenario, we could also deploy our model with Kubernetes, use authentication and authorization sidecar policies, and restrict network ingress and egress. Deploying a reproducible model in a packaged manner on Kubernetes to orchestrate the rest of the story can and will continue to improve our model’s security in layers.
For more on software supply chain, check out these resources:
https://www.sigstore.dev/
https://github.com/kubernetes-sigs/bom 

Conclusion
The goal of this chapter was to walk through a pseudo-model development and deployment in preparation for a discussion around the model development lifecycle. We learned about the model-application relationship, the value of reproducibility and replicability, and what technologies can help support our machine-learning initiative. 
